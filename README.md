# ğŸš§ Data Engineering Playground

This repository is a **personal workspace** for exploring, prototyping, and building data engineering solutions using **Python**, **PySpark**, **Airflow**, and **dbt**.

It contains structured subfolders with notebooks, dbt models, DAGs, and local development infrastructure for testing and learning.

---

## ğŸ“ Folder Structure

â”œâ”€â”€ dags/ # Apache Airflow DAGs
â”œâ”€â”€ docker-compose/ # Docker environment for local orchestration
â”œâ”€â”€ models/ # dbt models (ELT logic)
â”œâ”€â”€ notebooks/ # Jupyter/Databricks notebooks for EDA & pipeline prototyping
â”œâ”€â”€ stg/ # General staging code and raw transformations
â”œâ”€â”€ .user.yml # dbt user config
â”œâ”€â”€ dbt_project.yml # dbt project configuration
â”œâ”€â”€ profiles.yml # dbt profiles (connection setup)
â””â”€â”€ README.md # Project documentation


---

## ğŸ§° Tech Stack

- **Python 3.x**
- **Apache Spark (PySpark)**
- **Apache Airflow**
- **dbt (Data Build Tool)**
- **Docker / Docker Compose**
- Jupyter Notebooks

---

## âœ¨ Highlights

- End-to-end data transformation flows.
- Modular and testable DAGs with Airflow.
- Local development with `docker-compose`.
- dbt models for transforming raw/staged data.
- PySpark notebooks for handling large-scale data.

---

## ğŸš§ Disclaimer

This repo is under active development and serves as a testing ground. Some scripts and notebooks may be experimental or incomplete.

---

## ğŸ¤ Contributions

This is a personal project, but feel free to fork or explore if you find something useful. If you have questions or suggestions, feel free to open an issue or reach out.

